{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nltk_bleu mini-projectA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n",
        "Setup `fairseq` and install all required dependencies."
      ],
      "metadata": {
        "id": "day85CD3v33B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8XO0m5p4UtJZ",
        "outputId": "73d57b45-b7db-4c5b-ba15-3fa5ee188144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 31869, done.\u001b[K\n",
            "remote: Counting objects: 100% (354/354), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 31869 (delta 280), reused 321 (delta 248), pack-reused 31515\u001b[K\n",
            "Receiving objects: 100% (31869/31869), 21.76 MiB | 25.26 MiB/s, done.\n",
            "Resolving deltas: 100% (23466/23466), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+12fce77) (0.11.0+cu113)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting bitarray\n",
            "  Downloading bitarray-2.5.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+12fce77) (2019.12.20)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+12fce77) (0.29.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+12fce77) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+12fce77) (4.64.0)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+12fce77) (1.11.0+cu113)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+12fce77) (1.15.0)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+12fce77) (5.7.1)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+12fce77) (4.2.0)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.9 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+12fce77) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+12fce77) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+12fce77) (3.8.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=b85c8f92e1f8ca5e4e87d13d14b44eb2171a43a4555a312a108a755bfdfe7e21\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.5.1 colorama-0.4.4 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.4.0 sacrebleu-2.1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!git clone https://github.com/iakirca/fairseq\n",
        "os.chdir('fairseq')\n",
        "%pip install -e ./ \n",
        "\n",
        "#-e or --editable is needed for development \n",
        "#alternatively you can create your own fork and clone it instead every time you change the code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with autoreload you don't need to restart kernel after any changes\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "KwpcV1R_D4lO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sacremoses"
      ],
      "metadata": {
        "id": "0S5f0442veY4",
        "outputId": "c0de7382-70a2-41df-90d6-be9db33a96d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=77d2b6376ed95ebe09013d2fd91839c21b59dca456896e611615674af28fb49f\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data \n",
        "Data is typically has to be preprocessed. The pipline includes tokenization, truecasing, bpe splitting. Then, `fairseq-preprocess` is used to convert data into binary format.\n",
        "Since the data has been already preprocessed for you, you just need to access it. For that, mount your google drive. Fairseq-compatible data is stored in `ro-en-fairseq-bin` folder."
      ],
      "metadata": {
        "id": "pwDZg-aJvxtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "HhVeex7is34Q",
        "outputId": "070f099e-8a93-47c8-d60f-14491de83f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs5Fcs1Kk_07",
        "outputId": "3255e621-3794-435d-8a05-2e999e5e95fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.0-py3-none-any.whl (418 kB)\n",
            "\u001b[K     |████████████████████████████████| 418 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "Train CMLM model ([Ghazvininejad et. al., 2019](https://aclanthology.org/D19-1633/)) using `fairseq-hydra-train` command. You need to specify the config file (yaml config file example can be found in `model/train_config.yaml`). Trained baseline is avaliable under `model/model.pt`. You can load it as shown below.\n",
        "\n",
        "For details refer to https://github.com/pytorch/fairseq/blob/main/examples/nonautoregressive_translation/scripts.md#mask-predict-cmlm-ghazvininejad-et-al-2019"
      ],
      "metadata": {
        "id": "OAXeoERpv-J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "# %autoreload 0\n",
        "%run -i train.py /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin \\\n",
        "    --save-dir /content/drive/MyDrive/model_nltk_bleu \\\n",
        "    --restore-file /content/drive/MyDrive/mini-project-A/model/model.pt \\\n",
        "    --task translation_lev \\\n",
        "    --criterion rl_loss_nltk_bleu \\\n",
        "    --arch cmlm_transformer \\\n",
        "    --noise random_mask \\\n",
        "    --share-all-embeddings \\\n",
        "    --optimizer adam --adam-betas '(0.9,0.98)' \\\n",
        "    --lr 0.0005 --lr-scheduler inverse_sqrt \\\n",
        "    --stop-min-lr '1e-09' --warmup-updates 10000 \\\n",
        "    --warmup-init-lr '1e-07' \\\n",
        "    --dropout 0.3 --weight-decay 0.01 \\\n",
        "    --decoder-learned-pos \\\n",
        "    --encoder-learned-pos \\\n",
        "    --apply-bert-init \\\n",
        "    --log-format 'simple' --log-interval 100 \\\n",
        "    --fixed-validation-seed 7 \\\n",
        "    --max-tokens 4000 \\\n",
        "    --update-freq 2 \\\n",
        "    --save-interval-updates 10000 \\\n",
        "    --max-update 300000 \\\n",
        "    --max-epoch 124 \\\n",
        "    --reset-optimizer"
      ],
      "metadata": {
        "id": "Hmu0ErP0Jx2A",
        "outputId": "f4860a21-b41a-474e-8d7e-bce84f3dd23b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-05 10:45:17 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-06-05 10:45:22 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': 4000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 124, 'max_update': 300000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [0.0005], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/model_nltk_bleu', 'restore_file': '/content/drive/MyDrive/mini-project-A/model/model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 10000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='cmlm_transformer', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_bert_init=True, arch='cmlm_transformer', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='rl_loss_nltk_bleu', curriculum=0, data='/content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layers=6, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_learned_pos=True, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.0, left_pad_source=True, left_pad_target=False, length_loss_factor=0.1, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=124, max_tokens=4000, max_tokens_valid=4000, max_update=300000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, ngram_predictor=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_token_positional_embeddings=False, noise='random_mask', not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pred_length_offset=False, profile=False, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='/content/drive/MyDrive/mini-project-A/model/model.pt', save_dir='/content/drive/MyDrive/model_nltk_bleu', save_interval=1, save_interval_updates=10000, scoring='bleu', seed=1, sentence_avg=False, sg_length_pred=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, src_embedding_copy=False, stop_min_lr=1e-09, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation_lev', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[2], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=10000, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation_lev', 'data': '/content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False, 'noise': random_mask}, 'criterion': {'_name': 'rl_loss_nltk_bleu', 'label_smoothing': 0.0}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-06-05 10:45:23 | INFO | fairseq.tasks.translation | [ro] dictionary: 39720 types\n",
            "2022-06-05 10:45:23 | INFO | fairseq.tasks.translation | [en] dictionary: 39720 types\n",
            "2022-06-05 10:45:25 | INFO | fairseq_cli.train | CMLMNATransformerModel(\n",
            "  (encoder): FairseqNATEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(39720, 512, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): NATransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(39720, 512, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=39720, bias=False)\n",
            "    (embed_length): Embedding(256, 512)\n",
            "  )\n",
            ")\n",
            "2022-06-05 10:45:25 | INFO | fairseq_cli.train | task: TranslationLevenshteinTask\n",
            "2022-06-05 10:45:25 | INFO | fairseq_cli.train | model: CMLMNATransformerModel\n",
            "2022-06-05 10:45:25 | INFO | fairseq_cli.train | criterion: LabelSmoothedDualImitationCriterion\n",
            "2022-06-05 10:45:25 | INFO | fairseq_cli.train | num. shared model params: 65,656,832 (num. trained: 65,656,832)\n",
            "2022-06-05 10:45:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2022-06-05 10:45:26 | INFO | fairseq.data.data_utils | loaded 1,999 examples from: /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin/valid.ro-en.ro\n",
            "2022-06-05 10:45:26 | INFO | fairseq.data.data_utils | loaded 1,999 examples from: /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin/valid.ro-en.en\n",
            "2022-06-05 10:45:26 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin valid ro-en 1999 examples\n",
            "2022-06-05 10:45:38 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2022-06-05 10:45:38 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2022-06-05 10:45:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-06-05 10:45:38 | INFO | fairseq.utils | rank   0: capabilities =  6.0  ; total memory = 15.899 GB ; name = Tesla P100-PCIE-16GB                    \n",
            "2022-06-05 10:45:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-06-05 10:45:38 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-06-05 10:45:38 | INFO | fairseq_cli.train | max tokens per device = 4000 and max sentences per device = None\n",
            "2022-06-05 10:45:38 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/mini-project-A/model/model.pt\n",
            "2022-06-05 10:45:47 | INFO | fairseq.trainer | Loaded checkpoint /content/drive/MyDrive/mini-project-A/model/model.pt (epoch 123 @ 0 updates)\n",
            "2022-06-05 10:45:47 | INFO | fairseq.trainer | loading train data for epoch 123\n",
            "2022-06-05 10:45:49 | INFO | fairseq.data.data_utils | loaded 612,422 examples from: /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin/train.ro-en.ro\n",
            "2022-06-05 10:45:50 | INFO | fairseq.data.data_utils | loaded 612,422 examples from: /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin/train.ro-en.en\n",
            "2022-06-05 10:45:50 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin train ro-en 612422 examples\n",
            "2022-06-05 10:45:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2507\n",
            "2022-06-05 10:45:50 | INFO | fairseq.trainer | begin training epoch 123\n",
            "2022-06-05 10:45:50 | INFO | fairseq_cli.train | Start iterating over samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/content/fairseq/fairseq/utils.py:375: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-05 10:47:17 | INFO | train_inner | epoch 123:    824 / 2507 loss=1.635, nll_loss=None, word_ins=None, length=None, ppl=3.11, wps=7587.6, ups=1.07, wpb=7065.8, bsz=240.2, num_updates=100, lr=5.099e-06, gnorm=1.125, train_wall=86, gb_free=11.9, wall=0\n",
            "2022-06-05 10:48:45 | INFO | train_inner | epoch 123:    924 / 2507 loss=1.651, nll_loss=None, word_ins=None, length=None, ppl=3.14, wps=8034.9, ups=1.13, wpb=7123.1, bsz=231, num_updates=200, lr=1.0098e-05, gnorm=1.125, train_wall=88, gb_free=12, wall=0\n",
            "2022-06-05 10:50:13 | INFO | train_inner | epoch 123:   1024 / 2507 loss=1.674, nll_loss=None, word_ins=None, length=None, ppl=3.19, wps=8187.7, ups=1.14, wpb=7200.1, bsz=246.4, num_updates=300, lr=1.5097e-05, gnorm=1.1, train_wall=88, gb_free=11.9, wall=0\n",
            "2022-06-05 10:51:40 | INFO | train_inner | epoch 123:   1124 / 2507 loss=1.656, nll_loss=None, word_ins=None, length=None, ppl=3.15, wps=8359.2, ups=1.16, wpb=7217.8, bsz=269.1, num_updates=400, lr=2.0096e-05, gnorm=1.087, train_wall=86, gb_free=12.3, wall=0\n",
            "2022-06-05 10:53:08 | INFO | train_inner | epoch 123:   1224 / 2507 loss=1.722, nll_loss=None, word_ins=None, length=None, ppl=3.3, wps=7938.8, ups=1.13, wpb=7039.2, bsz=231.8, num_updates=500, lr=2.5095e-05, gnorm=1.149, train_wall=88, gb_free=12.2, wall=0\n",
            "2022-06-05 10:54:34 | INFO | train_inner | epoch 123:   1324 / 2507 loss=1.753, nll_loss=None, word_ins=None, length=None, ppl=3.37, wps=8261.7, ups=1.16, wpb=7094.5, bsz=264.9, num_updates=600, lr=3.0094e-05, gnorm=1.151, train_wall=85, gb_free=12.4, wall=0\n",
            "2022-06-05 10:56:03 | INFO | train_inner | epoch 123:   1424 / 2507 loss=1.818, nll_loss=None, word_ins=None, length=None, ppl=3.52, wps=8059.8, ups=1.12, wpb=7170.5, bsz=234.6, num_updates=700, lr=3.5093e-05, gnorm=1.148, train_wall=89, gb_free=12.5, wall=0\n",
            "2022-06-05 10:57:30 | INFO | train_inner | epoch 123:   1524 / 2507 loss=1.874, nll_loss=None, word_ins=None, length=None, ppl=3.66, wps=8199.8, ups=1.15, wpb=7131.6, bsz=244.7, num_updates=800, lr=4.0092e-05, gnorm=1.166, train_wall=87, gb_free=12.1, wall=0\n",
            "2022-06-05 10:58:58 | INFO | train_inner | epoch 123:   1624 / 2507 loss=2.038, nll_loss=None, word_ins=None, length=None, ppl=4.11, wps=8185.4, ups=1.14, wpb=7150.3, bsz=255.3, num_updates=900, lr=4.5091e-05, gnorm=1.176, train_wall=87, gb_free=12.3, wall=0\n",
            "2022-06-05 11:00:23 | INFO | train_inner | epoch 123:   1724 / 2507 loss=2.128, nll_loss=None, word_ins=None, length=None, ppl=4.37, wps=8232.9, ups=1.17, wpb=7019.2, bsz=248.3, num_updates=1000, lr=5.009e-05, gnorm=1.252, train_wall=85, gb_free=12.5, wall=0\n",
            "2022-06-05 11:01:48 | INFO | train_inner | epoch 123:   1824 / 2507 loss=2.524, nll_loss=None, word_ins=None, length=None, ppl=5.75, wps=8341.9, ups=1.17, wpb=7120, bsz=250.6, num_updates=1100, lr=5.5089e-05, gnorm=1.268, train_wall=85, gb_free=12, wall=0\n",
            "2022-06-05 11:03:16 | INFO | train_inner | epoch 123:   1924 / 2507 loss=2.996, nll_loss=None, word_ins=None, length=None, ppl=7.98, wps=8059.5, ups=1.14, wpb=7089, bsz=239.6, num_updates=1200, lr=6.0088e-05, gnorm=1.308, train_wall=88, gb_free=12, wall=0\n",
            "2022-06-05 11:04:43 | INFO | train_inner | epoch 123:   2024 / 2507 loss=3.715, nll_loss=None, word_ins=None, length=None, ppl=13.13, wps=8177.4, ups=1.15, wpb=7081.8, bsz=236.3, num_updates=1300, lr=6.5087e-05, gnorm=1.282, train_wall=86, gb_free=12.1, wall=0\n",
            "2022-06-05 11:06:11 | INFO | train_inner | epoch 123:   2124 / 2507 loss=4.176, nll_loss=None, word_ins=None, length=None, ppl=18.08, wps=8055.3, ups=1.13, wpb=7134, bsz=235.8, num_updates=1400, lr=7.0086e-05, gnorm=1.294, train_wall=88, gb_free=12.3, wall=0\n",
            "2022-06-05 11:07:37 | INFO | train_inner | epoch 123:   2224 / 2507 loss=3.932, nll_loss=None, word_ins=None, length=None, ppl=15.26, wps=8340.2, ups=1.17, wpb=7153.2, bsz=257.4, num_updates=1500, lr=7.5085e-05, gnorm=1.213, train_wall=85, gb_free=12.2, wall=0\n",
            "2022-06-05 11:09:03 | INFO | train_inner | epoch 123:   2324 / 2507 loss=4.435, nll_loss=None, word_ins=None, length=None, ppl=21.63, wps=8198, ups=1.16, wpb=7052.9, bsz=243.8, num_updates=1600, lr=8.0084e-05, gnorm=1.156, train_wall=86, gb_free=12, wall=0\n",
            "2022-06-05 11:10:30 | INFO | train_inner | epoch 123:   2424 / 2507 loss=3.782, nll_loss=None, word_ins=None, length=None, ppl=13.76, wps=8122.9, ups=1.15, wpb=7046.2, bsz=232.9, num_updates=1700, lr=8.5083e-05, gnorm=1.256, train_wall=86, gb_free=12.4, wall=0\n",
            "2022-06-05 11:11:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2022-06-05 11:11:45 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 2.534 | ppl 5.79 | wps 13523.5 | wpb 2675.3 | bsz 86.9 | num_updates 1783\n",
            "2022-06-05 11:11:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 1783 updates\n",
            "2022-06-05 11:11:45 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/model_nltk_bleu/checkpoint123.pt\n",
            "2022-06-05 11:11:49 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/model_nltk_bleu/checkpoint123.pt\n",
            "2022-06-05 11:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/model_nltk_bleu/checkpoint123.pt (epoch 123 @ 1783 updates, score 2.534) (writing took 19.435341425999923 seconds)\n",
            "2022-06-05 11:12:05 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)\n",
            "2022-06-05 11:12:05 | INFO | train | epoch 123 | loss 2.901 | nll_loss 1.724 | word_ins 3.474 | length 2.747 | ppl 7.47 | wps 8147.7 | ups 0.69 | wpb 11762.4 | bsz 405.3 | num_updates 1783 | lr 8.92322e-05 | gnorm 1.157 | train_wall 2796 | gb_free 12.4 | wall 0\n",
            "2022-06-05 11:12:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2507\n",
            "2022-06-05 11:12:05 | INFO | fairseq.trainer | begin training epoch 124\n",
            "2022-06-05 11:12:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2022-06-05 11:12:28 | INFO | train_inner | epoch 124:     17 / 2507 loss=2.441, nll_loss=None, word_ins=None, length=None, ppl=5.43, wps=6049.5, ups=0.85, wpb=7144, bsz=265.9, num_updates=1800, lr=9.0082e-05, gnorm=1.308, train_wall=93, gb_free=12.1, wall=0\n",
            "2022-06-05 11:13:52 | INFO | train_inner | epoch 124:    117 / 2507 loss=1.94, nll_loss=None, word_ins=None, length=None, ppl=3.84, wps=8410.2, ups=1.19, wpb=7038.8, bsz=238.9, num_updates=1900, lr=9.5081e-05, gnorm=0.967, train_wall=83, gb_free=12, wall=0\n",
            "2022-06-05 11:15:18 | INFO | train_inner | epoch 124:    217 / 2507 loss=1.711, nll_loss=None, word_ins=None, length=None, ppl=3.27, wps=8232.4, ups=1.15, wpb=7141.1, bsz=239.2, num_updates=2000, lr=0.00010008, gnorm=1.272, train_wall=86, gb_free=12.3, wall=0\n",
            "2022-06-05 11:16:44 | INFO | train_inner | epoch 124:    317 / 2507 loss=3.643, nll_loss=None, word_ins=None, length=None, ppl=12.49, wps=8139.3, ups=1.16, wpb=7006.6, bsz=228.9, num_updates=2100, lr=0.000105079, gnorm=1.667, train_wall=86, gb_free=12.3, wall=0\n",
            "2022-06-05 11:18:09 | INFO | train_inner | epoch 124:    417 / 2507 loss=3.113, nll_loss=None, word_ins=None, length=None, ppl=8.65, wps=8390.1, ups=1.18, wpb=7130.1, bsz=255.5, num_updates=2200, lr=0.000110078, gnorm=1.622, train_wall=85, gb_free=12, wall=0\n",
            "2022-06-05 11:19:37 | INFO | train_inner | epoch 124:    517 / 2507 loss=2.958, nll_loss=None, word_ins=None, length=None, ppl=7.77, wps=8192.5, ups=1.14, wpb=7182.6, bsz=243.9, num_updates=2300, lr=0.000115077, gnorm=1.755, train_wall=87, gb_free=12.3, wall=0\n",
            "2022-06-05 11:21:01 | INFO | train_inner | epoch 124:    617 / 2507 loss=1.381, nll_loss=None, word_ins=None, length=None, ppl=2.6, wps=8428.2, ups=1.19, wpb=7110.4, bsz=234.2, num_updates=2400, lr=0.000120076, gnorm=1.122, train_wall=84, gb_free=12, wall=0\n",
            "2022-06-05 11:22:26 | INFO | train_inner | epoch 124:    717 / 2507 loss=1.692, nll_loss=None, word_ins=None, length=None, ppl=3.23, wps=8444.1, ups=1.18, wpb=7152, bsz=239, num_updates=2500, lr=0.000125075, gnorm=1.535, train_wall=84, gb_free=12.2, wall=0\n",
            "2022-06-05 11:23:51 | INFO | train_inner | epoch 124:    817 / 2507 loss=2.389, nll_loss=None, word_ins=None, length=None, ppl=5.24, wps=8389.6, ups=1.18, wpb=7122.9, bsz=272.7, num_updates=2600, lr=0.000130074, gnorm=1.848, train_wall=85, gb_free=12, wall=0\n",
            "2022-06-05 11:25:15 | INFO | train_inner | epoch 124:    917 / 2507 loss=3.569, nll_loss=None, word_ins=None, length=None, ppl=11.87, wps=8441.2, ups=1.18, wpb=7125.7, bsz=255.9, num_updates=2700, lr=0.000135073, gnorm=1.366, train_wall=84, gb_free=12.2, wall=0\n",
            "2022-06-05 11:26:41 | INFO | train_inner | epoch 124:   1017 / 2507 loss=2.735, nll_loss=None, word_ins=None, length=None, ppl=6.66, wps=8201, ups=1.17, wpb=7027.4, bsz=237, num_updates=2800, lr=0.000140072, gnorm=1.904, train_wall=85, gb_free=12.1, wall=0\n",
            "2022-06-05 11:28:06 | INFO | train_inner | epoch 124:   1117 / 2507 loss=1.399, nll_loss=None, word_ins=None, length=None, ppl=2.64, wps=8476.3, ups=1.18, wpb=7182.3, bsz=241.9, num_updates=2900, lr=0.000145071, gnorm=1.563, train_wall=84, gb_free=12.3, wall=0\n",
            "2022-06-05 11:29:31 | INFO | train_inner | epoch 124:   1217 / 2507 loss=2.238, nll_loss=None, word_ins=None, length=None, ppl=4.72, wps=8432.9, ups=1.18, wpb=7140.3, bsz=257.8, num_updates=3000, lr=0.00015007, gnorm=1.889, train_wall=84, gb_free=12.2, wall=0\n",
            "2022-06-05 11:30:55 | INFO | train_inner | epoch 124:   1317 / 2507 loss=2.03, nll_loss=None, word_ins=None, length=None, ppl=4.09, wps=8459.4, ups=1.18, wpb=7178.2, bsz=243.2, num_updates=3100, lr=0.000155069, gnorm=1.415, train_wall=84, gb_free=12.7, wall=0\n",
            "2022-06-05 11:32:18 | INFO | train_inner | epoch 124:   1417 / 2507 loss=1.727, nll_loss=None, word_ins=None, length=None, ppl=3.31, wps=8599.9, ups=1.21, wpb=7094.7, bsz=255.5, num_updates=3200, lr=0.000160068, gnorm=2.112, train_wall=82, gb_free=12.2, wall=0\n",
            "2022-06-05 11:33:44 | INFO | train_inner | epoch 124:   1517 / 2507 loss=2.604, nll_loss=None, word_ins=None, length=None, ppl=6.08, wps=8238.2, ups=1.17, wpb=7061.1, bsz=221.3, num_updates=3300, lr=0.000165067, gnorm=1.439, train_wall=85, gb_free=12.2, wall=0\n",
            "2022-06-05 11:35:07 | INFO | train_inner | epoch 124:   1617 / 2507 loss=1.911, nll_loss=None, word_ins=None, length=None, ppl=3.76, wps=8544, ups=1.19, wpb=7151.8, bsz=259.8, num_updates=3400, lr=0.000170066, gnorm=0.62, train_wall=83, gb_free=12.2, wall=0\n",
            "2022-06-05 11:36:30 | INFO | train_inner | epoch 124:   1717 / 2507 loss=1.497, nll_loss=None, word_ins=None, length=None, ppl=2.82, wps=8554.8, ups=1.2, wpb=7106.1, bsz=261.4, num_updates=3500, lr=0.000175065, gnorm=1.41, train_wall=83, gb_free=12, wall=0\n",
            "2022-06-05 11:37:56 | INFO | train_inner | epoch 124:   1817 / 2507 loss=2.373, nll_loss=None, word_ins=None, length=None, ppl=5.18, wps=8271.6, ups=1.16, wpb=7105.7, bsz=231.6, num_updates=3600, lr=0.000180064, gnorm=0.798, train_wall=85, gb_free=12.1, wall=0\n",
            "2022-06-05 11:39:19 | INFO | train_inner | epoch 124:   1917 / 2507 loss=1.686, nll_loss=None, word_ins=None, length=None, ppl=3.22, wps=8536.1, ups=1.21, wpb=7075.5, bsz=238.6, num_updates=3700, lr=0.000185063, gnorm=0.528, train_wall=82, gb_free=12.1, wall=0\n",
            "2022-06-05 11:40:46 | INFO | train_inner | epoch 124:   2017 / 2507 loss=2.907, nll_loss=None, word_ins=None, length=None, ppl=7.5, wps=8326.8, ups=1.16, wpb=7189.1, bsz=233.4, num_updates=3800, lr=0.000190062, gnorm=0.437, train_wall=86, gb_free=12.2, wall=0\n",
            "2022-06-05 11:42:11 | INFO | train_inner | epoch 124:   2117 / 2507 loss=2.33, nll_loss=None, word_ins=None, length=None, ppl=5.03, wps=8479.2, ups=1.17, wpb=7226.5, bsz=258.1, num_updates=3900, lr=0.000195061, gnorm=0.439, train_wall=85, gb_free=12.2, wall=0\n",
            "2022-06-05 11:43:33 | INFO | train_inner | epoch 124:   2217 / 2507 loss=1.093, nll_loss=None, word_ins=None, length=None, ppl=2.13, wps=8581.4, ups=1.21, wpb=7082.6, bsz=237.5, num_updates=4000, lr=0.00020006, gnorm=0.437, train_wall=82, gb_free=12.2, wall=0\n",
            "2022-06-05 11:44:58 | INFO | train_inner | epoch 124:   2317 / 2507 loss=1.335, nll_loss=None, word_ins=None, length=None, ppl=2.52, wps=8425.2, ups=1.18, wpb=7121.4, bsz=247.7, num_updates=4100, lr=0.000205059, gnorm=0.404, train_wall=84, gb_free=11.9, wall=0\n",
            "2022-06-05 11:46:23 | INFO | train_inner | epoch 124:   2417 / 2507 loss=1.526, nll_loss=None, word_ins=None, length=None, ppl=2.88, wps=8400.1, ups=1.18, wpb=7147.7, bsz=241, num_updates=4200, lr=0.000210058, gnorm=0.42, train_wall=85, gb_free=12.1, wall=0\n",
            "2022-06-05 11:47:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2022-06-05 11:47:43 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 1.553 | ppl 2.93 | wps 13936.3 | wpb 2675.3 | bsz 86.9 | num_updates 4290 | best_loss 1.553\n",
            "2022-06-05 11:47:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 4290 updates\n",
            "2022-06-05 11:47:43 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/model_nltk_bleu/checkpoint124.pt\n",
            "2022-06-05 11:47:48 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/model_nltk_bleu/checkpoint124.pt\n",
            "2022-06-05 11:48:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/model_nltk_bleu/checkpoint124.pt (epoch 124 @ 4290 updates, score 1.553) (writing took 21.411092827000175 seconds)\n",
            "2022-06-05 11:48:05 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)\n",
            "2022-06-05 11:48:05 | INFO | train | epoch 124 | loss 2.114 | nll_loss None | word_ins None | length None | ppl 4.33 | wps 8257 | ups 1.16 | wpb 7113.8 | bsz 244.3 | num_updates 4290 | lr 0.000214557 | gnorm 1.176 | train_wall 2123 | gb_free 12.1 | wall 0\n",
            "2022-06-05 11:48:05 | INFO | fairseq_cli.train | done training in 3734.4 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers"
      ],
      "metadata": {
        "id": "c66h57EiBjTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c462897b-b2e7-41a5-c626-21bc7fba6e7b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.7.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets unbabel-comet\n"
      ],
      "metadata": {
        "id": "pHzdWINdB0LE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e40b5b5-4fb6-47e3-ccfe-81245d7b61bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting unbabel-comet\n",
            "  Downloading unbabel_comet-1.1.1-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 18.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Collecting dill<0.3.5\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 17.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 13.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 12.3 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning==1.6.0\n",
            "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 19.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from unbabel-comet) (3.17.3)\n",
            "Requirement already satisfied: sacrebleu>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from unbabel-comet) (2.1.0)\n",
            "Requirement already satisfied: transformers>=4.8 in /usr/local/lib/python3.7/dist-packages (from unbabel-comet) (4.19.2)\n",
            "Collecting jsonargparse==3.13.1\n",
            "  Downloading jsonargparse-3.13.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting scipy>=1.5.4\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from unbabel-comet) (1.11.0+cu113)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchmetrics>=0.7 in /usr/local/lib/python3.7/dist-packages (from unbabel-comet) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.6.0->unbabel-comet) (2.8.0)\n",
            "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->unbabel-comet) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=2.0.0->unbabel-comet) (2019.12.20)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=2.0.0->unbabel-comet) (0.8.9)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=2.0.0->unbabel-comet) (0.4.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=2.0.0->unbabel-comet) (2.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (1.46.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (3.3.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0->unbabel-comet) (3.2.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8->unbabel-comet) (0.12.1)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 50.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, pyDeprecate, dill, xxhash, sentencepiece, scipy, responses, pytorch-lightning, pandas, multiprocess, jsonargparse, unbabel-comet, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.13\n",
            "    Uninstalling multiprocess-0.70.13:\n",
            "      Successfully uninstalled multiprocess-0.70.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 dill-0.3.4 frozenlist-1.3.0 fsspec-2022.5.0 jsonargparse-3.13.1 multidict-6.0.2 multiprocess-0.70.12.2 pandas-1.1.5 pyDeprecate-0.3.2 pytorch-lightning-1.6.0 responses-0.18.0 scipy-1.7.3 sentencepiece-0.1.96 unbabel-comet-1.1.1 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dill",
                  "scipy",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation\n",
        "Generate output for the test data using `fairseq-generate` and stored checkpoint\n",
        "\n",
        "See https://github.com/pytorch/fairseq/blob/main/examples/nonautoregressive_translation/README.md#translate for more details"
      ],
      "metadata": {
        "id": "CMcchHJNhUqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i fairseq_cli/generate.py /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin \\\n",
        "--path /content/drive/MyDrive/model_nltk_bleu/NLTK_bleu_checkpoint_best.pt \\\n",
        "--batch-size 16 --beam 1 --task translation_lev --iter-decode-max-iter 9 \\\n",
        "--gen-subset test --remove-bpe --scoring bleu --tokenizer moses \\\n",
        "--source-lang ro --target-lang en --quiet "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjrJh657isJ3",
        "outputId": "e39d0666-9232-471e-a9ed-eff45d68d047"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-05 12:53:28 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/drive/MyDrive/model_nltk_bleu/NLTK_bleu_checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 1, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 9, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation_lev', 'data': '/content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin', 'source_lang': 'ro', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False, 'noise': 'random_delete'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': {'_name': 'moses', 'source_lang': 'ro', 'target_lang': 'en', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-06-05 12:53:29 | INFO | fairseq.tasks.translation | [ro] dictionary: 39720 types\n",
            "2022-06-05 12:53:29 | INFO | fairseq.tasks.translation | [en] dictionary: 39720 types\n",
            "2022-06-05 12:53:29 | INFO | fairseq_cli.generate | loading model(s) from /content/drive/MyDrive/model_nltk_bleu/NLTK_bleu_checkpoint_best.pt\n",
            "2022-06-05 12:53:33 | INFO | fairseq.data.data_utils | loaded 1,999 examples from: /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin/test.ro-en.ro\n",
            "2022-06-05 12:53:33 | INFO | fairseq.data.data_utils | loaded 1,999 examples from: /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin/test.ro-en.en\n",
            "2022-06-05 12:53:33 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/mini-project-A/ro-en-fairseq-bin test ro-en 1999 examples\n",
            "2022-06-05 12:54:01 | INFO | fairseq.logging.progress_bar | :    101 / 126 wps=1300\n",
            "2022-06-05 12:54:12 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-06-05 12:54:12 | INFO | fairseq_cli.generate | Translated 1,999 sentences (55,954 tokens) in 21.3s (93.78 sentences/s, 2624.96 tokens/s)\n",
            "Generate test with beam=1: BLEU4 = 0.19, 4.2/0.7/0.2/0.0 (BP=0.492, ratio=0.585, syslen=24645, reflen=42105)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jpHnKh_idYfB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}